{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='C:\\\\Users\\\\Kelvin-PC\\\\OneDrive - The Chinese University of Hong Kong\\\\Documents\\\\Github\\\\CSCI3320_PROJECT\\\\csci3320_prj\\\\data\\\\training.csv' mode='r' encoding='cp1252'>\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\Kelvin-PC\\\\OneDrive - The Chinese University of Hong Kong\\\\Documents\\\\Github\\\\CSCI3320_PROJECT\\\\csci3320_prj\\\\data\\\\testing.csv' mode='r' encoding='cp1252'>\n",
      "Logistic----------------------------------------------------------------------------------\n",
      "       race_id horse_id HorseWin HorseRankTop3 HorseRankTop50Percent\n",
      "1     2016-328     A009        1             1                     1\n",
      "2     2016-328     T157        1             1                     1\n",
      "3     2016-328     S098        0             0                     0\n",
      "4     2016-328     S329        0             0                     0\n",
      "5     2016-328     V273        1             1                     1\n",
      "6     2016-328     P085        0             0                     0\n",
      "7     2016-328     V117        0             0                     0\n",
      "8     2016-328     S442        0             1                     1\n",
      "9     2016-328     V011        1             1                     1\n",
      "10    2016-328     V084        0             0                     0\n",
      "11    2016-328     A082        0             0                     0\n",
      "12    2016-328     T267        0             0                     0\n",
      "13    2016-329     T391        0             0                     0\n",
      "14    2016-329     P256        1             1                     1\n",
      "15    2016-329     S335        0             0                     1\n",
      "16    2016-329     V212        1             1                     1\n",
      "17    2016-329     S407        1             1                     1\n",
      "18    2016-329     T113        1             1                     1\n",
      "19    2016-329     P421        0             0                     1\n",
      "20    2016-329     T031        0             0                     0\n",
      "21    2016-329     T314        1             1                     1\n",
      "22    2016-329     P145        0             0                     0\n",
      "23    2016-329     S303        0             0                     0\n",
      "24    2016-329     N443        0             0                     0\n",
      "25    2016-330     T406        1             1                     1\n",
      "26    2016-330     V279        0             0                     0\n",
      "27    2016-330     T369        0             0                     0\n",
      "28    2016-330     T426        0             1                     1\n",
      "29    2016-330     V053        0             0                     1\n",
      "30    2016-330     T046        1             1                     1\n",
      "...        ...      ...      ...           ...                   ...\n",
      "5835  2016-805     S362        1             1                     1\n",
      "5836  2016-805     A163        1             1                     1\n",
      "5837  2016-805     A249        0             0                     0\n",
      "5838  2016-805     A352        1             1                     1\n",
      "5839  2016-806     A257        1             1                     1\n",
      "5840  2016-806     A287        0             0                     0\n",
      "5841  2016-806     S419        1             1                     1\n",
      "5842  2016-806     V379        1             1                     1\n",
      "5843  2016-806     V235        0             0                     0\n",
      "5844  2016-806     V256        1             1                     1\n",
      "5845  2016-806     P396        0             1                     1\n",
      "5846  2016-806     A006        0             0                     0\n",
      "5847  2016-806     A217        0             0                     0\n",
      "5848  2016-806     A337        1             1                     1\n",
      "5849  2016-806     V250        0             0                     0\n",
      "5850  2016-806     V118        0             0                     1\n",
      "5851  2016-807     T242        0             0                     0\n",
      "5852  2016-807     V214        0             0                     0\n",
      "5853  2016-807     A098        0             0                     0\n",
      "5854  2016-807     S358        0             0                     0\n",
      "5855  2016-807     A041        0             0                     0\n",
      "5856  2016-807     T375        0             0                     0\n",
      "5857  2016-807     V372        0             1                     1\n",
      "5858  2016-807     V186        1             1                     1\n",
      "5859  2016-807     T396        0             0                     0\n",
      "5860  2016-807     A183        0             0                     0\n",
      "5861  2016-807     V099        0             0                     0\n",
      "5862  2016-807     S298        0             0                     0\n",
      "5863  2016-807     T371        0             1                     1\n",
      "5864  2016-807     V411        0             1                     1\n",
      "\n",
      "[5864 rows x 5 columns]\n",
      "Gaussian------------------------------------------------------------------------------------\n",
      "       race_id horse_id HorseWin HorseRankTop3 HorseRankTop50Percent\n",
      "1     2016-328     A009        0             1                     1\n",
      "2     2016-328     T157        0             1                     1\n",
      "3     2016-328     S098        0             0                     0\n",
      "4     2016-328     S329        0             0                     0\n",
      "5     2016-328     V273        1             1                     1\n",
      "6     2016-328     P085        0             0                     0\n",
      "7     2016-328     V117        0             0                     0\n",
      "8     2016-328     S442        0             1                     1\n",
      "9     2016-328     V011        1             1                     1\n",
      "10    2016-328     V084        0             0                     0\n",
      "11    2016-328     A082        0             0                     0\n",
      "12    2016-328     T267        0             0                     0\n",
      "13    2016-329     T391        0             0                     0\n",
      "14    2016-329     P256        0             1                     1\n",
      "15    2016-329     S335        0             0                     1\n",
      "16    2016-329     V212        1             1                     1\n",
      "17    2016-329     S407        0             1                     1\n",
      "18    2016-329     T113        0             1                     1\n",
      "19    2016-329     P421        0             0                     0\n",
      "20    2016-329     T031        0             0                     0\n",
      "21    2016-329     T314        1             1                     1\n",
      "22    2016-329     P145        0             0                     0\n",
      "23    2016-329     S303        0             0                     0\n",
      "24    2016-329     N443        0             0                     0\n",
      "25    2016-330     T406        0             1                     1\n",
      "26    2016-330     V279        0             0                     0\n",
      "27    2016-330     T369        0             0                     0\n",
      "28    2016-330     T426        0             0                     0\n",
      "29    2016-330     V053        0             0                     1\n",
      "30    2016-330     T046        1             1                     1\n",
      "...        ...      ...      ...           ...                   ...\n",
      "5835  2016-805     S362        0             0                     1\n",
      "5836  2016-805     A163        0             1                     1\n",
      "5837  2016-805     A249        0             0                     0\n",
      "5838  2016-805     A352        1             1                     1\n",
      "5839  2016-806     A257        1             1                     1\n",
      "5840  2016-806     A287        0             0                     0\n",
      "5841  2016-806     S419        0             1                     1\n",
      "5842  2016-806     V379        1             1                     1\n",
      "5843  2016-806     V235        0             0                     0\n",
      "5844  2016-806     V256        0             1                     1\n",
      "5845  2016-806     P396        0             0                     0\n",
      "5846  2016-806     A006        0             0                     0\n",
      "5847  2016-806     A217        0             0                     0\n",
      "5848  2016-806     A337        0             1                     1\n",
      "5849  2016-806     V250        0             0                     0\n",
      "5850  2016-806     V118        0             0                     1\n",
      "5851  2016-807     T242        0             0                     0\n",
      "5852  2016-807     V214        0             0                     0\n",
      "5853  2016-807     A098        0             0                     0\n",
      "5854  2016-807     S358        0             0                     0\n",
      "5855  2016-807     A041        0             0                     0\n",
      "5856  2016-807     T375        0             0                     0\n",
      "5857  2016-807     V372        0             0                     0\n",
      "5858  2016-807     V186        1             1                     1\n",
      "5859  2016-807     T396        0             0                     0\n",
      "5860  2016-807     A183        0             0                     0\n",
      "5861  2016-807     V099        0             0                     0\n",
      "5862  2016-807     S298        0             0                     0\n",
      "5863  2016-807     T371        1             1                     1\n",
      "5864  2016-807     V411        0             0                     0\n",
      "\n",
      "[5864 rows x 5 columns]\n",
      "['1' '2' '3' ..., '9' '10' '11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:110: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1f84144e5fb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mnb_pre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import csv\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#3.1.1 Logistic Regression\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "#h = .02  # step size in the mesh\n",
    "direct = 'data'\n",
    "def get_data(name = ''):\n",
    "    df = \"\"\n",
    "    path = os.getcwd()\n",
    "    direct='data'\n",
    "    file=os.path.join(path,direct, name)\n",
    "    #opencsv=\"\"\n",
    "    try:\n",
    "        opencsv = open(os.path.join(path,direct,name), 'r')\n",
    "        print(opencsv)#find the race-result-horse file\n",
    "    except:\n",
    "        while opencsv != name:  # if the file cant be found if there is an error\n",
    "            print(\"Could not open \", \"file\")\n",
    "            opencsv = input(\"\\nPlease try to open file again: \")\n",
    "    else:\n",
    "        with open(os.path.join(path,direct,name)) as f:\n",
    "            feature_names = []#f.readline()\n",
    "            #print(feature_names)\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                feature_names = row \n",
    "                #print(feature_names)\n",
    "                break\n",
    "            df =  pd.read_csv(open(os.path.join(path,direct,name)), header=None, names = feature_names) #, na_values = ['WV-A' , 'WV'])\n",
    "            df.drop(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "def process(df = pd.DataFrame({}), a=[]):\n",
    "    for i in range(5864):\n",
    "        if a[i] == 1:\n",
    "            i=i+1\n",
    "            #print(\"Hi my frd\")\n",
    "            df.loc[i, 'HorseWin'] = 1\n",
    "            df.loc[i, 'HorseRankTop3'] = 1\n",
    "            df.loc[i, 'HorseRankTop50Percent'] = 1\n",
    "        elif a[i] == 2 or a[i] == 3:\n",
    "            i=i+1\n",
    "            df.loc[i, 'HorseWin'] = 0\n",
    "            df.loc[i, 'HorseRankTop3'] = 1\n",
    "            df.loc[i, 'HorseRankTop50Percent'] = 1\n",
    "        elif a[i] == 4 or a[i] == 5 or a[i] == 6:\n",
    "            i=i+1\n",
    "            df.loc[i, 'HorseWin'] = 0\n",
    "            df.loc[i, 'HorseRankTop3'] = 0\n",
    "            df.loc[i, 'HorseRankTop50Percent'] = 1\n",
    "        else:\n",
    "            i=i+1\n",
    "            df.loc[i, 'HorseWin'] = 0\n",
    "            df.loc[i, 'HorseRankTop3'] = 0\n",
    "            df.loc[i, 'HorseRankTop50Percent'] = 0\n",
    "    return df\n",
    "\n",
    "df1 = get_data('training.csv')\n",
    "df2 = get_data('testing.csv')\n",
    "#a = map(int, df1.iloc('recent_6_runs').split(\"/\"))\n",
    "#print(a)\n",
    "#a=(df1[\"recent_6_runs\"].values)\n",
    "#for i in a:\n",
    "#    i=i.split(\"/\")\n",
    "    \n",
    "df1.recent_ave_rank = df1.recent_ave_rank.astype(int)\n",
    "df1[\"HorseWin\"] = \"\"\n",
    "df1[\"HorseRankTop3\"] = \"\"\n",
    "df1[\"HorseRankTop50Percent\"] = \"\"\n",
    "df2[\"HorseWin\"] = \"\"\n",
    "df2[\"HorseRankTop3\"] = \"\"\n",
    "df2[\"HorseRankTop50Percent\"] = \"\"\n",
    "\n",
    "#19: RaceID; 4: HorseID; 21: RecentAvg rank\n",
    "#24: JockeyAbg rank; 26: TrainerAvg rank\n",
    "X_train = df1.loc[:,['jockey_ave_rank','trainer_ave_rank','actual_weight','declared_horse_weight']] #24,26\n",
    "Y_train = df1.loc[:,['finishing_position']]\n",
    "X_test = df2.loc[:,['jockey_ave_rank','trainer_ave_rank','actual_weight','declared_horse_weight']] #no problem\n",
    "\n",
    "print(\"Logistic----------------------------------------------------------------------------------\")\n",
    "lr_model = linear_model.LogisticRegression(random_state=0)\n",
    "lr_model.fit(X_train, np.ravel(Y_train)) \n",
    "lr_pre = lr_model.predict(X_test)\n",
    "lr_pre = list(map(int, lr_pre))\n",
    "dflr = process(df2,lr_pre)\n",
    "lr_result = dflr.iloc[:,[19,4,28,29,30]]\n",
    "print(lr_result)\n",
    "lr_result.to_csv(os.path.join(direct,'lr_preductions.csv') , encoding = \"utf-8\" )\n",
    "\n",
    "print(\"Gaussian------------------------------------------------------------------------------------\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, np.ravel(Y_train))\n",
    "#GaussianNB(priors=None)\n",
    "nb_pre = nb_model.predict(X_test)\n",
    "nb_pre = list(map(int, nb_pre))\n",
    "#print(nb_pre)\n",
    "df2 = process(df2,nb_pre)\n",
    "nb_result = df2.iloc[:,[19,4,28,29,30]]\n",
    "print(nb_result)\n",
    "nb_result.to_csv(os.path.join(direct,'nb_preductions.csv') , encoding = \"utf-8\" )\n",
    "\n",
    "'''\n",
    "print(\"Multinomial----------------------------------------------------------------------------------\")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "nb_pre = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Bernoulli------------------------------------------------------------------------------------\")\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_model = BernoulliNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "nb_pre = nb_model.predict(X_test)\n",
    "'''\n",
    "\n",
    "\n",
    "print(\"SVM------------------------------------------------------------------------------------\")\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(random_state=0)\n",
    "svm_model.fit(X_train, np.ravel(Y_train))\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "svm_pre = svm_model.predict(X_test)\n",
    "svm_pre = list(map(int, svm_pre))\n",
    "df2 = process(df2,svm_pre)\n",
    "svm_result = df2.iloc[:,[19,4,28,29,30]]\n",
    "print(svm_result)\n",
    "svm_result.to_csv(os.path.join(direct,'svm_preductions.csv') , encoding = \"utf-8\" )\n",
    "\n",
    "print(\"Random Forest-----------------------------------------------------------------------------\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "rf_model = RandomForestClassifier(random_state=0) #max_depth=2, random_state=0\n",
    "rf_model.fit(X_train, np.ravel(Y_train))\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#rf_model.feature_importances_\n",
    "rf_pre = rf_model.predict(X_test)\n",
    "rf_pre = list(map(int, rf_pre))\n",
    "df2 = process(df2,rf_pre)\n",
    "rf_result = df2.iloc[:,[19,4,28,29,30]]\n",
    "print(rf_result)\n",
    "rf_result.to_csv(os.path.join(direct,'rf_preductions.csv') , encoding = \"utf-8\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
