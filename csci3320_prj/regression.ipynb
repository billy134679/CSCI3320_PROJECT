{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tang Ying Kin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate , cross_val_predict\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn\n",
    "import os\n",
    "import csv\n",
    "#import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_data(name = ''):\n",
    "    df = \"\"\n",
    "    path = os.getcwd()\n",
    "    direct='data'\n",
    "    file=os.path.join(path,direct, name)\n",
    "    #opencsv=\"\"\n",
    "    try:\n",
    "        opencsv = open(os.path.join(path,direct,name), 'r')\n",
    "        #print(opencsv)#find the race-result-horse file\n",
    "    except:\n",
    "        while opencsv != name:  # if the file cant be found if there is an error\n",
    "            print(\"Could not open \", \"file\")\n",
    "            opencsv = input(\"\\nPlease try to open file again: \")\n",
    "    else:\n",
    "        with open(os.path.join(path,direct,name)) as f:\n",
    "            feature_names = []#f.readline()\n",
    "            #print(feature_names)\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                feature_names = row\n",
    "                #print(feature_names)\n",
    "                break\n",
    "            df =  pd.read_csv(open(os.path.join(path,direct,name)), header=None, names = feature_names) #, na_values = ['WV-A' , 'WV'])\n",
    "            df.drop(0, inplace = True)\n",
    "    return df\n",
    "    \n",
    "def get_list(df = [] , col_type = ''):\n",
    "    list_set = np.empty(0)\n",
    "    for index, row in df.iterrows():\n",
    "        #print(row[col_type])\n",
    "        if not row[col_type] in list_set:\n",
    "            list_set = np.append(list_set , row[col_type])\n",
    "    return list_set\n",
    "    \n",
    "    \n",
    "    \n",
    "def finish_time(df = pd.DataFrame({})):\n",
    "    for index , row in df.iterrows():\n",
    "        \n",
    "        _min , _sec , _fract = row['finish_time'].split(\".\")\n",
    "       # print(_min , _sec, _fract)\n",
    "        time = (float)( int(_min)*60 + int(_sec) + int(_fract) /100 )\n",
    "        df.loc[index , 'finish_time'] = time\n",
    "        #print(\"df finish_time: \",df.loc[index , 'finish_time'])\n",
    "        #print(type(df.loc[index,'finish_time']) )\n",
    "        \n",
    "\n",
    "def svr_(X, y , X_test , ker = 'linear' , C = 1 , epsilon = 0.1):\n",
    "    svr_model = SVR(kernel = ker , degree=3, gamma = 'auto', coef0=0.0, tol=0.001, C=C,\n",
    "        epsilon= epsilon, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "    svr_model.fit(X,y)\n",
    "    #print(\"cross_val_score:\")\n",
    "    #print(cross_val_score(svr_model , X , y , cv = 10 ,n_jobs = -1 ))\n",
    "    print(\"SVR with {0} kernel score: {1}\".format(ker , svr_model.score(X,y)) )\n",
    "    return svr_model.predict(X_test)\n",
    "    \n",
    "def GBRT_(X,y , X_test, loss = 'ls' , learning_rate = 0.1 , n_estimators = 100 , max_depth = 3):\n",
    "    gbrt_model = GradientBoostingRegressor(loss = loss , learning_rate = learning_rate , \n",
    "                                          n_estimators = n_estimators , max_depth = max_depth)\n",
    "    gbrt_model.fit(X,y)\n",
    "    #print(\"gbrt cross_val_score:\")\n",
    "    #print(cross_val_score(gbrt_model , X , y , cv = 10 ,n_jobs = -1) )\n",
    "    print(\"GBRT score: {0}\".format(gbrt_model.score(X,y)) )\n",
    "\n",
    "    return gbrt_model.predict(X_test)\n",
    "\n",
    "def evaluation(prediction = [] , label = [] , model = 'SVR' , df = pd.DataFrame({}) , wif = 'with'):\n",
    "    rmse = math.sqrt(mean_squared_error(label  , prediction) )\n",
    "    print(\"\\n\\nEvaluation of \",model,\"model\",wif,\"normalization\")\n",
    "    print(\"\\nRoot mean square error = %.4f\"%rmse)\n",
    "\n",
    "    race_info = pd.DataFrame({\n",
    "        'df_id':df.index.values,\n",
    "        'finish_time':df.loc[:,['finish_time']].values.ravel(),\n",
    "        'prediction':prediction,\n",
    "        'unique_horse_id':df.loc[:,['unique_horse_id']].values.ravel(),\n",
    "        'race_id':df.loc[:,['race_id']].values.ravel(),\n",
    "        'finishing_position':df.loc[:,['finishing_position']].values.ravel()\n",
    "    })\n",
    "    \n",
    "    #print(\"Race_info:\")\n",
    "    #print(race_info.shape)\n",
    "    \n",
    "    race_list = get_list(race_info , 'race_id')\n",
    "    #print(race_list.shape)\n",
    "    \n",
    "    top1_rank = 0\n",
    "    top3_rank = 0\n",
    "    \n",
    "    predict_top1_arr = pd.DataFrame([] , columns = ['unique_horse_id' , 'top1' , 'top3' , 'actual_rank'])\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(race_list.shape[0]):\n",
    "        race_for_sort = race_info[race_info[\"race_id\"] == race_list[i]].reset_index(drop = True)\n",
    "        race_sorted = race_for_sort.sort_values(by = ['prediction'] ).reset_index(drop = True)\n",
    "        #print(race_sorted)\n",
    "        \n",
    "        \n",
    "        \n",
    "        predict_top1_arr.loc[count , ['unique_horse_id']] = race_sorted.loc[0,['unique_horse_id']]\n",
    "        if int(race_sorted.loc[0 , 'finishing_position']) == 1:\n",
    "            predict_top1_arr.loc[count , ['top1']] = True\n",
    "        else:\n",
    "            predict_top1_arr.loc[count , ['top1']] = False\n",
    "        \n",
    "        if int(race_sorted.loc[0 , 'finishing_position']) <=3:\n",
    "            predict_top1_arr.loc[count , ['top3']] = True\n",
    "        else:\n",
    "            predict_top1_arr.loc[count , ['top3']] = False\n",
    "        \n",
    "        predict_top1_arr.loc[count , ['actual_rank']] = int(race_sorted.loc[0 , ['finishing_position']])        \n",
    "        \n",
    "        count = count +1\n",
    "    \n",
    "    #print(predict_top1_arr)\n",
    "    print(\"Top1_accuracy: \" , predict_top1_arr.loc[:,['top1']].values.sum() / predict_top1_arr.shape[0])\n",
    "    print(\"Top3_accuracy: \" , predict_top1_arr.loc[:,['top3']].values.sum()/predict_top1_arr.shape[0])\n",
    "    print(\"Average Rank of all predicted top1 horse: %.4f\" %(predict_top1_arr.loc[:,['actual_rank']].values.sum()/predict_top1_arr.shape[0]) )\n",
    "    \n",
    "    top1_horse_eval = [['horse_id' , 'Top_1' , 'Top_3' , 'ave_rank']]\n",
    "    #pd.DataFrame([] , columns = ['unique_horse_id' , 'top1' ,'top3' , 'ave_rank'])\n",
    "    top1_horse_list = get_list(predict_top1_arr , 'unique_horse_id')\n",
    "    count = 0\n",
    "    #print(top1_horse_list.shape)\n",
    "    #print(top1_horse_eval)\n",
    "    \n",
    "    for horse_id in top1_horse_list.flatten():\n",
    "        #print(\"first top1 prediction\",horse_id)\n",
    "        win_horse = predict_top1_arr[predict_top1_arr[\"unique_horse_id\"] == horse_id]\n",
    "        #print(win_horse.shape)\n",
    "        _append = [  horse_id , float(win_horse.loc[:,['top1']].values.sum() / win_horse.shape[0]), \n",
    "                                     float(win_horse.loc[:,['top3']].values.sum() / win_horse.shape[0]),\n",
    "                                    int(round(win_horse.loc[:,['actual_rank']].values.sum() / win_horse.shape[0] ))   ]\n",
    "        #print(np.shape(_append) )\n",
    "        top1_horse_eval.append(_append)\n",
    "        #top1_horse_eval.loc[count , ['unique_horse_id']] = horse_id\n",
    "        #top1_horse_eval.loc[count , ['top1']] = float(win_horse.loc[:,['top1']].values.sum() / win_horse.shape[0])\n",
    "        #top1_horse_eval.loc[count , ['top3']] = float(win_horse.loc[:,['top3']].values.sum() / win_horse.shape[0])\n",
    "        #top1_horse_eval.loc[count , ['ave_rank']] = int(round(win_horse.loc[:,['actual_rank']].values.sum() / win_horse.shape[0] ))\n",
    "        #print(np.shape(top1_horse_eval))\n",
    "        count = count+1\n",
    "        #if count >3:\n",
    "            #break\n",
    "        #print(horse_id)\n",
    "        #print(\"P(Top1) =\", float(win_horse.loc[:,['top1']].values.sum() / win_horse.shape[0]) )\n",
    "        #print(\"P(Top3) =\", float(win_horse.loc[:,['top3']].values.sum() / win_horse.shape[0]) )\n",
    "        #print(\"Average Rank =\", int(round(win_horse.loc[:,['actual_rank']].values.sum() / win_horse.shape[0] )) )\n",
    "        \n",
    "    top1_horse_eval = np.array(top1_horse_eval)\n",
    "    top1_horse_eval = pd.DataFrame(data = top1_horse_eval[1:,] , columns = top1_horse_eval[0 , 0:])\n",
    "    #print(top1_horse_eval)\n",
    "    #return top1_horse_eval\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def regression():\n",
    "    df_train = get_data('training.csv') #load data\n",
    "    df_test = get_data('testing.csv')\n",
    "    #print(df_train.describe())\n",
    "    #print(\"training set: \",df_train.shape[0])\n",
    "    #print(\"testing set: \",df_test.shape[0])\n",
    "    #print(get_list(df_test , 'race_id').shape)\n",
    "    finish_time(df_train)  #change finish_time column from str to float\n",
    "    finish_time(df_test)\n",
    "    \n",
    "    X_train_src = df_train.loc[:, ['actual_weight' , 'declared_horse_weight' , 'draw' , 'win_odds' , 'jockey_ave_rank'\n",
    "                                  ,'trainer_ave_rank' , 'recent_ave_rank' , 'race_distance'] ]\n",
    "    y_train_src = df_train.loc[:, ['finish_time'] ]\n",
    "    \n",
    "    X_test_src = df_test.loc[:, ['actual_weight' , 'declared_horse_weight' , 'draw' , 'win_odds' , 'jockey_ave_rank'\n",
    "                                  ,'trainer_ave_rank' , 'recent_ave_rank' , 'race_distance'] ]\n",
    "    \n",
    "    y_test_src = df_test.loc[:, ['finish_time'] ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(X_train_src.loc[1].values)\n",
    "    \n",
    "    X_scaler = StandardScaler()\n",
    "    \n",
    "    X_scaler.fit(X_train_src)\n",
    "    \n",
    "    X_train_scaled = X_scaler.transform(X_train_src)  # cannot use test data for StandardScaler fitting so use training data instead\n",
    "    \n",
    "    X_test_scaled = X_scaler.transform(X_test_src)\n",
    "    \n",
    "    X_scaler.fit(y_train_src)\n",
    "    \n",
    "    y_train_scaled = X_scaler.transform(y_train_src)\n",
    "    \n",
    "    y_test_scaled = X_scaler.transform(y_test_src)\n",
    "    \n",
    "    #print(X_train_scaled[0] , X_test_scaled[0])\n",
    "    \n",
    "    #svr_(X_train_scaled , y_train_scaled.ravel() , 'linear' , 4 , 0.4 )\n",
    "    svr_wif_norm_predict = svr_(X_train_scaled , y_train_scaled.ravel() ,X_test_scaled   \n",
    "                                                     ,'linear' , 2 , 0.2)   #SVR model   linear: C = 2 , 0.2 best\n",
    "    #X_scaler.fit(y_train_src)\n",
    "    svr_wif_norm_predict = X_scaler.inverse_transform(svr_wif_norm_predict)\n",
    "    svr_wifo_norm_predict =svr_(X_train_src.values , y_train_src.values.ravel() , X_test_src.values ,'linear', 2, 0.2)\n",
    "    #svr_(X_train_scaled , y_train_scaled.ravel() , 'poly' , 2.5 ,0.1)\n",
    "    #svr_(X_train_scaled , y_train_scaled.ravel() , 'sigmoid' , 2.5 , 0.1)\n",
    "    #svr_(X_train_scaled , y_train_scaled.ravel() , 'precomputed')\n",
    "    \n",
    "    gbrt_wif_norm_predict  = GBRT_(X_train_scaled , y_train_scaled.ravel() ,X_test_scaled,\n",
    "          'ls' , 0.2 , 200 , 6 )  #GBRT model\n",
    "    gbrt_wif_norm_predict = X_scaler.inverse_transform(gbrt_wif_norm_predict)\n",
    "    \n",
    "    gbrt_wifo_norm_predict = GBRT_(X_train_src.values , y_train_src.values.ravel() , X_test_src.values ,\n",
    "          'ls' , 0.2 , 200 , 6 )\n",
    "                     \n",
    "    evaluation(svr_wif_norm_predict , y_test_src.values.ravel() , \"SVR\" ,df_test , \"with\")  #evaluation part\n",
    "    evaluation(svr_wifo_norm_predict , y_test_src.values.ravel() , \"SVR\" , df_test , \"without\")\n",
    "    evaluation(gbrt_wif_norm_predict , y_test_src.values.ravel() , 'GBRT' , df_test , \"with\")\n",
    "    evaluation(gbrt_wifo_norm_predict , y_test_src.values.ravel() , 'GBRT' , df_test, \"without\")\n",
    "    ################################## regression model implementation\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with linear kernel score: 0.9916590853391136\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    regression()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
